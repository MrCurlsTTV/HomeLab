---
# File: Ansible\inventory\hosts.yml
all:
  children:
    kubernetes:
      children:
        rke2_servers:
          hosts:
            k8s-master-0:
              ansible_host: "172.16.10.200"
              rke2_role: server
              node_labels:
                - "node.kubernetes.io/control-plane=true"
                - "node.kubernetes.io/master=true"
            k8s-master-1:
              ansible_host: "172.16.10.201"
              rke2_role: server
              node_labels:
                - "node.kubernetes.io/control-plane=true"
                - "node.kubernetes.io/master=true"
            k8s-master-2:
              ansible_host: "172.16.10.202"
              rke2_role: server
              node_labels:
                - "node.kubernetes.io/control-plane=true"
                - "node.kubernetes.io/master=true"
          vars:
            ansible_ssh_user: ansible
            ansible_ssh_private_key_file: ~/.ssh/id_rsa
            ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
        rke2_agents:
          hosts:
            k8s-worker-1:
              ansible_host: "172.16.10.210"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
            k8s-worker-2:
              ansible_host: "172.16.10.211"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
            k8s-worker-3:
              ansible_host: "172.16.10.212"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
            k8s-worker-4:
              ansible_host: "172.16.10.213"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
            k8s-worker-5:
              ansible_host: "172.16.10.214"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
            k8s-worker-6:
              ansible_host: "172.16.10.215"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
            k8s-worker-7:
              ansible_host: "172.16.10.216"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
            k8s-worker-8:
              ansible_host: "172.16.10.217"
              rke2_role: agent
              node_labels:
                - "node.kubernetes.io/worker=true"
                - "node.kubernetes.io/role=worker"
          vars:
            ansible_ssh_user: ansible
            ansible_ssh_private_key_file: ~/.ssh/id_rsa
            ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
      vars:
        ansible_user: ansible
        ansible_become: true
        ansible_become_method: sudo
    storage:
      hosts:
        nas:
          ansible_host: "192.168.103.2"
      vars:
        ansible_ssh_user: root
        ansible_ssh_private_key_file: ~/.ssh/id_rsa
        ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
        ansible_become: false 
